{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ts1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/data/chronos/AAPL.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m ts2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/data/chronos/ADBE.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts1 = pd.read_parquet(r\"/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/data/chronos/AAPL.parquet\")\n",
    "ts2 = pd.read_parquet(r\"/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/data/chronos/ADBE.parquet\")\n",
    "df_combined = pd.concat([ts1, ts2], ignore_index=False)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "# input_dir = '/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/embeddings'\n",
    "\n",
    "# for cluster_name in os.listdir(input_dir):\n",
    "#     cluster_path = os.path.join(input_dir, cluster_name)\n",
    "#     print(cluster_path)\n",
    "\n",
    "#     if os.path.isdir(cluster_path) and cluster_name.startswith('cluster_'):\n",
    "#         dfs = []\n",
    "\n",
    "#         for file in os.listdir(cluster_path):\n",
    "#             if file.endswith('.parquet'):\n",
    "#                 file_path = os.path.join(cluster_path, file)\n",
    "#                 df = pd.read_parquet(file_path)\n",
    "#                 dfs.append(df)\n",
    "\n",
    "#         if dfs:\n",
    "#             df_combined = pd.concat(dfs, ignore_index=False)\n",
    "            \n",
    "#             # Optional: validate index is multi-index\n",
    "#             if not isinstance(df_combined.index, pd.MultiIndex):\n",
    "#                 raise ValueError(f\"{cluster_name}: Combined DataFrame does not have a MultiIndex.\")\n",
    "\n",
    "#             # Save combined DataFrame\n",
    "#             output_path = os.path.join(input_dir, f\"{cluster_name}_combined.parquet\")\n",
    "#             df_combined.to_parquet(output_path)\n",
    "#             print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/statistical/cluster_1\n",
      "Saved: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/statistical/cluster_1_combined.parquet\n",
      "Processing: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/statistical/cluster_2\n",
      "Saved: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/statistical/cluster_2_combined.parquet\n",
      "Processing: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/statistical/cluster_3\n",
      "Saved: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/statistical/cluster_3_combined.parquet\n",
      "Processing: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/statistical/cluster_4\n",
      "Saved: /Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/statistical/cluster_4_combined.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_dir = '/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/statistical'\n",
    "output_dir = '/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/statistical'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Sort cluster folders numerically\n",
    "cluster_dirs = sorted(\n",
    "    [d for d in os.listdir(input_dir) if d.startswith('cluster_')],\n",
    "    key=lambda x: int(x.split('_')[1])\n",
    ")\n",
    "\n",
    "for cluster_name in cluster_dirs:\n",
    "    cluster_path = os.path.join(input_dir, cluster_name)\n",
    "    print(f\"Processing: {cluster_path}\")\n",
    "\n",
    "    if os.path.isdir(cluster_path):\n",
    "        dfs = []\n",
    "\n",
    "        for file in os.listdir(cluster_path):\n",
    "            if file.endswith('.parquet'):\n",
    "                file_path = os.path.join(cluster_path, file)\n",
    "                df = pd.read_parquet(file_path)\n",
    "                dfs.append(df)\n",
    "\n",
    "        if dfs:\n",
    "            df_combined = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "            if not isinstance(df_combined.index, pd.MultiIndex):\n",
    "                raise ValueError(f\"{cluster_name}: Combined DataFrame does not have a MultiIndex.\")\n",
    "\n",
    "            # Save to specified output folder\n",
    "            output_path = os.path.join(output_dir, f\"{cluster_name}_combined.parquet\")\n",
    "            df_combined.to_parquet(output_path)\n",
    "            print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BMY</th>\n",
       "      <th>2022-03-21 09:30:00</th>\n",
       "      <td>0.765269</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.776546</td>\n",
       "      <td>0.765328</td>\n",
       "      <td>0.269982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21 10:30:00</th>\n",
       "      <td>0.756571</td>\n",
       "      <td>0.765189</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.763164</td>\n",
       "      <td>0.178066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21 11:30:00</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.756493</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.756432</td>\n",
       "      <td>0.123280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21 12:30:00</th>\n",
       "      <td>0.748231</td>\n",
       "      <td>0.749583</td>\n",
       "      <td>0.750089</td>\n",
       "      <td>0.753946</td>\n",
       "      <td>0.138182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21 13:30:00</th>\n",
       "      <td>0.748588</td>\n",
       "      <td>0.748153</td>\n",
       "      <td>0.748183</td>\n",
       "      <td>0.751382</td>\n",
       "      <td>0.122192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Close      Open      High       Low    Volume\n",
       "item_id timestamp                                                            \n",
       "BMY     2022-03-21 09:30:00  0.765269  0.765309  0.776546  0.765328  0.269982\n",
       "        2022-03-21 10:30:00  0.756571  0.765189  0.764629  0.763164  0.178066\n",
       "        2022-03-21 11:30:00  0.749660  0.756493  0.755929  0.756432  0.123280\n",
       "        2022-03-21 12:30:00  0.748231  0.749583  0.750089  0.753946  0.138182\n",
       "        2022-03-21 13:30:00  0.748588  0.748153  0.748183  0.751382  0.122192"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "comby = pd.read_parquet(r\"/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters_appended_ts/embeddings/cluster_0_combined.parquet\")\n",
    "comby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5108, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comby.loc[\"ADBE\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BMY', 'NVDA', 'XOM', 'GM', 'AAPL', 'UL', 'VZ', 'ADBE', 'MSFT', 'ORCL',\n",
       "       'PG'],\n",
       "      dtype='object', name='item_id')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_item_ids = comby.index.get_level_values('item_id').unique()\n",
    "unique_item_ids\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
