{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_stock_series(directory):\n",
    "    stock_series = {}\n",
    "    stock_file_paths = {}\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.parquet'):\n",
    "                symbol = filename.split('.')[0]\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                stock_series[symbol] = pd.read_parquet(file_path)\n",
    "                stock_file_paths[symbol] = file_path\n",
    "                logging.info(f\"✅ File {filename} successfully loaded.\")\n",
    "        return stock_series, stock_file_paths\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"❌ Directory {directory} not found: {e}.\")\n",
    "        return {}, {}\n",
    "    \n",
    "\n",
    "def compute_dtw_distance_matrix(stock_series, column='Close'):\n",
    "    symbols = list(stock_series.keys())\n",
    "    n = len(symbols)\n",
    "    dtw_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        series_i = np.asarray(stock_series[symbols[i]][column]).squeeze().flatten()\n",
    "        if series_i.ndim != 1:\n",
    "            logging.error(f\"❌ Series for {symbols[i]} is not 1-D after flatten, shape: {series_i.shape}\")\n",
    "            raise ValueError(f\"Series for {symbols[i]} is not 1-D after flatten, shape: {series_i.shape}\")\n",
    "\n",
    "        for j in range(i + 1, n):\n",
    "            series_j = np.asarray(stock_series[symbols[j]][column]).squeeze().flatten()\n",
    "            if series_j.ndim != 1:\n",
    "                logging.error(f\"❌ Series for {symbols[j]} is not 1-D after flatten, shape: {series_j.shape}\")\n",
    "                raise ValueError(f\"Series for {symbols[j]} is not 1-D after flatten, shape: {series_j.shape}\")\n",
    "\n",
    "            distance, _ = fastdtw(series_i, series_j, dist=lambda x, y: abs(x - y))\n",
    "            dtw_matrix[i, j] = distance\n",
    "            dtw_matrix[j, i] = distance\n",
    "\n",
    "    logging.info(\"✅ DTW distance matrix computation complete.\")\n",
    "    return dtw_matrix, symbols\n",
    "\n",
    "\n",
    "def hierarchical_clustering_dtw(dtw_matrix, symbols, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering on the DTW distance matrix.\n",
    "\n",
    "    Parameters:\n",
    "        dtw_matrix (np.array): DTW distance matrix.\n",
    "        symbols (list): List of stock symbols corresponding to the matrix indices.\n",
    "        n_clusters (int): Number of clusters to form.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of stock symbol to assigned cluster label.\n",
    "    \"\"\"\n",
    "    condensed_matrix = squareform(dtw_matrix)\n",
    "    linked = linkage(condensed_matrix, method='ward')\n",
    "    cluster_labels = fcluster(linked, n_clusters, criterion='maxclust')\n",
    "\n",
    "    clusters = {symbol: cluster for symbol, cluster in zip(symbols, cluster_labels)}\n",
    "    logging.info(\"Hierarchical clustering complete.\")\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def save_stocks_to_cluster_dirs(clusters, data_directory, output_directory):\n",
    "    try:\n",
    "        cluster_dirs = {cluster: os.path.join(output_directory, f\"cluster_{cluster}\")\n",
    "                        for cluster in set(clusters.values())}\n",
    "        for path in cluster_dirs.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        for stock, cluster in clusters.items():\n",
    "            source_file = os.path.join(data_directory, f\"{stock}.parquet\")\n",
    "            dest_file = os.path.join(cluster_dirs[cluster], f\"{stock}.parquet\")\n",
    "            if os.path.exists(source_file):\n",
    "                shutil.copy(source_file, dest_file)\n",
    "                logging.info(f\"Copied {stock}.parquet to cluster_{cluster} directory.\")\n",
    "            else:\n",
    "                logging.warning(f\"❌ File {source_file} not found!\")\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"❌ Directory {data_directory} not found: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = r\"/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/data/chronos\"\n",
    "    output_directory = r\"/Users/akramchakrouni/Projects/time-series-forecasting-cluserting/clusters/dtw\"\n",
    "    n_clusters = 5\n",
    "\n",
    "    stock_series, stock_file_paths = load_all_stock_series(data_directory)\n",
    "    dtw_matrix, symbols = compute_dtw_distance_matrix(stock_series, column='Close')\n",
    "    clusters = hierarchical_clustering_dtw(dtw_matrix, symbols, n_clusters=n_clusters)\n",
    "\n",
    "    save_stocks_to_cluster_dirs(clusters, data_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding ideal amount of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 2\n",
      "Best silhouette score: 0.6212347846302031\n",
      "Scores for each k: {2: 0.6212347846302031, 3: 0.35761369428187617, 4: 0.37768199606192765, 5: 0.32130582084910864, 6: 0.3248682867115323, 7: 0.30652267040939823, 8: 0.3172446176425021, 9: 0.24567084205401182, 10: 0.23804313443212055}\n"
     ]
    }
   ],
   "source": [
    "def find_best_num_clusters(distance_matrix, method='ward', min_k=2, max_k=10):\n",
    "    \"\"\"\n",
    "    Try different numbers of clusters (k) for hierarchical clustering\n",
    "    and compute the silhouette score for each. Return the best k.\n",
    "\n",
    "    Parameters:\n",
    "        distance_matrix (np.ndarray): Your precomputed DTW distance matrix (NxN).\n",
    "        method (str): Linkage method to use ('ward', 'complete', etc.).\n",
    "        min_k (int): Minimum number of clusters to try.\n",
    "        max_k (int): Maximum number of clusters to try.\n",
    "\n",
    "    Returns:\n",
    "        best_k (int): The number of clusters that yields the best silhouette score.\n",
    "        best_score (float): The best silhouette score found.\n",
    "        scores_dict (dict): A dictionary of k -> silhouette score.\n",
    "    \"\"\"\n",
    "    # Condense the NxN matrix into a 1D array for scipy’s hierarchical clustering\n",
    "    condensed = squareform(distance_matrix)\n",
    "    \n",
    "    # Perform hierarchical clustering once outside the loop\n",
    "    # (linkage can be reused for different cluster cuts)\n",
    "    Z = linkage(condensed, method=method)\n",
    "\n",
    "    best_k = min_k\n",
    "    best_score = -1\n",
    "    scores_dict = {}\n",
    "\n",
    "    for k in range(min_k, max_k + 1):\n",
    "        # Cut the dendrogram to form k clusters\n",
    "        cluster_labels = fcluster(Z, k, criterion='maxclust')\n",
    "\n",
    "        # Compute silhouette score on the distance matrix\n",
    "        # metric='precomputed' means we pass the NxN distance matrix directly\n",
    "        score = silhouette_score(distance_matrix, cluster_labels, metric='precomputed')\n",
    "\n",
    "        scores_dict[k] = score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    return best_k, best_score, scores_dict\n",
    "\n",
    "best_k, best_score, all_scores = find_best_num_clusters(dtw_matrix, method='ward', min_k=2, max_k=10)\n",
    "print(\"Best number of clusters:\", best_k)\n",
    "print(\"Best silhouette score:\", best_score)\n",
    "print(\"Scores for each k:\", all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters: 45\n"
     ]
    }
   ],
   "source": [
    "def find_best_num_clusters_kneedle(distance_matrix, method='ward'):\n",
    "    \"\"\"\n",
    "    Determine the optimal number of clusters using the elbow method and the kneedle algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        distance_matrix (np.ndarray): Precomputed DTW distance matrix (NxN).\n",
    "        method (str): Linkage method to use (e.g., 'ward', 'complete', etc.).\n",
    "    \n",
    "    Returns:\n",
    "        best_k (int): The number of clusters suggested by the elbow.\n",
    "        Z (np.ndarray): The linkage matrix used for clustering.\n",
    "    \"\"\"\n",
    "    # Convert the full (NxN) distance matrix to condensed form.\n",
    "    condensed = squareform(distance_matrix)\n",
    "    # Compute the linkage matrix.\n",
    "    Z = linkage(condensed, method=method)\n",
    "    n = distance_matrix.shape[0]\n",
    "    \n",
    "    # In hierarchical clustering, each row in Z corresponds to a merge.\n",
    "    # When there are n points, Z has (n-1) rows.\n",
    "    # The number of clusters after each merge goes from n down to 1.\n",
    "    # We extract the merge distances (Z[:, 2]) and reverse them so they correspond \n",
    "    # to cluster counts from n down to 2.\n",
    "    cluster_counts = np.arange(n, 1, -1)\n",
    "    rev_distances = Z[:, 2][::-1]\n",
    "    \n",
    "    # Use the KneeLocator to detect the \"knee\" in the plot of cluster count vs. merge distance.\n",
    "    # The knee point represents a significant jump in the merging distance.\n",
    "    kneedle = KneeLocator(cluster_counts, rev_distances, curve='convex', direction='increasing')\n",
    "    best_k = kneedle.knee if kneedle.knee is not None else n // 2  # Fallback if no knee detected\n",
    "\n",
    "    logging.info(f\"Optimal number of clusters suggested by the elbow: {best_k}\")\n",
    "    return best_k, Z\n",
    "\n",
    "# Example usage:\n",
    "best_k, Z = find_best_num_clusters_kneedle(dtw_matrix, method='ward')\n",
    "print(\"Optimal number of clusters:\", best_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eosl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
